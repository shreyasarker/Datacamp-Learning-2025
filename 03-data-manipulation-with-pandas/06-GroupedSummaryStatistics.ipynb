{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0032c3",
   "metadata": {},
   "source": [
    "## Grouped Summary Statistics\n",
    "\n",
    "**Grouped summary statistics** are a powerful way to analyze data by dividing it into categories and computing descriptive statistics for each group. This allows for more insightful, segmented analysis rather than relying solely on overall statistics.\n",
    "\n",
    "### Purpose of Grouped Statistics\n",
    "\n",
    "Grouped statistics help answer questions like:\n",
    "\n",
    "* How does the average sales differ across store types?\n",
    "* What is the maximum unemployment rate for each year?\n",
    "* Which department generates the highest revenue in each store?\n",
    "\n",
    "They allow you to identify trends, patterns, and outliers within specific groups of your data.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "You group the data based on one or more categorical columns (like store, department, or year), and then apply summary functions (like mean, sum, or median) to numerical columns. This helps break down large datasets into smaller, more manageable pieces of analysis.\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "* Comparing performance metrics across different categories (e.g., store types, departments)\n",
    "* Summarizing data per group for reporting or visualization\n",
    "* Identifying top-performing segments\n",
    "* Analyzing time-based trends within groups (like yearly averages)\n",
    "\n",
    "### Things to Remember\n",
    "\n",
    "* Grouped results are usually indexed by the grouping column(s)\n",
    "* Multiple summary statistics can be calculated for each group\n",
    "* Grouping can be hierarchical, such as grouping by both store and department\n",
    "* Grouped summary statistics provide context-specific insights that raw totals can't\n",
    "\n",
    "Grouped statistics are essential in exploratory data analysis, business intelligence, and machine learning feature engineering — offering a deeper and more structured understanding of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a863d37",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e218d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv(\"datasets/sales_subset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8fa23",
   "metadata": {},
   "source": [
    "## Exercise: What percent of sales occurred at each store type?\n",
    "\n",
    "Instead of relying on `.groupby()`, you can figure out summary values just by filtering the data and summing up.\n",
    "\n",
    "Walmart’s dataset marks stores as type **\"A\"** (supercenters), **\"B\"** (discount stores), and **\"C\"** (neighborhood markets). In this task, you’ll calculate the contribution of each store type to the company’s overall sales.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Add up all values in `weekly_sales` to get the grand total.\n",
    "2. Extract rows for type `\"A\"` and compute their sales total.\n",
    "3. Do the same for type `\"B\"` and `\"C\"`.\n",
    "4. Put the results for A, B, and C into a list and divide by the overall total to find their proportions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10f7343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.9097746968515047), np.float64(0.09022530314849538), np.float64(0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Overall weekly sales across all stores\n",
    "all_sales = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Step 2: Sales totals by store type\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Step 3: Proportion of sales by store type\n",
    "proportion_by_type = [\n",
    "    sales_A / all_sales,\n",
    "    sales_B / all_sales,\n",
    "    sales_C / all_sales\n",
    "]\n",
    "\n",
    "print(proportion_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fac2e",
   "metadata": {},
   "source": [
    "## Exercise: Calculations with .groupby()\n",
    "\n",
    "The `.groupby()` method is a powerful way to summarize your data. In this task, you’ll repeat the sales breakdown by store type, but this time with `.groupby()`. You’ll also see how grouping by more than one column (store type and holiday indicator) lets you compare sales patterns more flexibly.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Group the data by the column `\"type\"`, calculate the sum of `\"weekly_sales\"`, and save it as `totals_by_type`.\n",
    "2. Find the share of sales for each store type by dividing `totals_by_type` by the overall sum. Store the result as `proportion_by_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70739e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Sum of weekly sales for each store type\n",
    "totals_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Step 2: Proportion of sales by type\n",
    "proportion_by_type = totals_by_type / totals_by_type.sum()\n",
    "\n",
    "print(proportion_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703c5e6",
   "metadata": {},
   "source": [
    "\n",
    "The `.groupby()` method isn’t limited to just a single column—you can pass in multiple columns to get even deeper insights. In this exercise, you’ll extend your previous analysis by checking whether weekly sales vary not only by store type, but also by whether the week was a holiday.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Start by grouping the data by `\"type\"` and summing `\"weekly_sales\"`. Save this as `totals_by_type`.\n",
    "2. Next, group the data by both `\"type\"` and `\"is_holiday\"`, summing `\"weekly_sales\"`, and assign it to `totals_by_type_holiday`.\n",
    "3. Print out the result to inspect sales across store types for holiday vs. non-holiday weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ca9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Total weekly sales by store type\n",
    "totals_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Step 2: Total weekly sales by store type and holiday flag\n",
    "totals_by_type_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "\n",
    "print(totals_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527385a",
   "metadata": {},
   "source": [
    "## Exercise: Multiple grouped summaries\n",
    "\n",
    "The `.agg()` method is handy when you want to calculate several summary measures at once. It works seamlessly on grouped data too. With it, you can quickly compute descriptive statistics such as minimum, maximum, average, and median values.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. For each store type, calculate the `min`, `max`, `mean`, and `median` of `weekly_sales`. Save this as `sales_stats`.\n",
    "2. Do the same for the columns `unemployment` and `fuel_price_usd_per_l`, grouped by store type, and store the result in `unemp_fuel_stats`.\n",
    "3. Print both results to explore the summary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3deaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         min        max          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n",
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "              min    max      mean median                  min       max   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:4: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:4: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:4: FutureWarning: The provided callable <function mean at 0x000001A1EFF3EB60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:4: FutureWarning: The provided callable <function median at 0x000001A1F00A07C0> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:9: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  .agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:9: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  .agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:9: FutureWarning: The provided callable <function mean at 0x000001A1EFF3EB60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  .agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:9: FutureWarning: The provided callable <function median at 0x000001A1F00A07C0> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  .agg([min, max, np.mean, np.median])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_19868\\2070717077.py:9: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  .agg([min, max, np.mean, np.median])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Weekly sales stats by store type\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
    "print(sales_stats)\n",
    "\n",
    "# Step 2: Unemployment and fuel price stats by store type\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]] \\\n",
    "                        .agg([min, max, np.mean, np.median])\n",
    "print(unemp_fuel_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
