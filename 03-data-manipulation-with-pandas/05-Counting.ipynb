{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a481c202",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c668454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv(\"datasets/sales_subset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04ad0a",
   "metadata": {},
   "source": [
    "## Exercise: Dropping duplicates\n",
    "\n",
    "Duplicate entries can skew your analysis, especially when you're counting or summarizing data. In this task, you'll clean the dataset by eliminating duplicate combinations from certain columns in the `sales` DataFrame.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Remove duplicate combinations** of `store` and `type`.\n",
    "2. **Remove duplicate combinations** of `store` and `department`.\n",
    "3. **Identify unique holiday dates** by filtering on `is_holiday` and dropping duplicates based on `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13a3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique store-type combinations:\n",
      "       Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove duplicate combinations of store and type\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(\"Unique store-type combinations:\\n\", store_types.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2c35c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique store-department combinations:\n",
      "     Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove duplicate combinations of store and department\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(\"Unique store-department combinations:\\n\", store_depts.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0306b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holiday Dates:\n",
      " 498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3. Filter holiday weeks and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset=\"date\")\n",
    "\n",
    "# 4. Display the unique holiday dates\n",
    "print(\"Holiday Dates:\\n\", holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c08f95",
   "metadata": {},
   "source": [
    "## Counting categorical variables\n",
    "\n",
    "Counting is an excellent technique to summarize categorical data and uncover interesting patterns. In this task, you’ll explore the distribution of store types and department numbers using the cleaned DataFrames you previously created.\n",
    "\n",
    "You’ll work with:\n",
    "\n",
    "* `store_types`: Contains unique combinations of `store` and `type`\n",
    "* `store_depts`: Contains unique combinations of `store` and `department`\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Calculate the count** of each store `type` in `store_types`.\n",
    "2. **Compute the proportion** (relative frequency) of each store `type`.\n",
    "3. **Find the count** of each `department` in `store_depts`, sorted in **descending** order.\n",
    "4. **Determine the proportion** of each `department`, also sorted in **descending** order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0ba3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    11\n",
      "B     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many stores belong to each store type\n",
    "store_type_counts = store_types['type'].value_counts()\n",
    "print(store_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07233e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of each store type\n",
    "store_type_proportions = store_types['type'].value_counts(normalize=True)\n",
    "print(store_type_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6317c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "1     12\n",
      "2     12\n",
      "3     12\n",
      "4     12\n",
      "5     12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: count, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many stores carry each department\n",
    "# By default, value_counts() sorts results in descending order\n",
    "department_counts = store_depts['department'].value_counts()\n",
    "print(department_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf00b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "1     0.012917\n",
      "2     0.012917\n",
      "3     0.012917\n",
      "4     0.012917\n",
      "5     0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: proportion, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of stores carrying each department\n",
    "department_proportions = store_depts['department'].value_counts(normalize=True)\n",
    "print(department_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769f219",
   "metadata": {},
   "source": [
    "#### Key Note:\n",
    "\n",
    "* `value_counts()` returns a Series sorted in **descending order** by default, so there's no need to pass `sort=True`.\n",
    "* Using `normalize=True` returns **proportions** instead of counts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
