{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234ffc0f",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc81d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"region\": [\n",
    "        \"East South Central\", \"Pacific\", \"Mountain\", \"West South Central\", \"Pacific\", \"Mountain\", \"New England\",\n",
    "        \"South Atlantic\", \"South Atlantic\", \"South Atlantic\", \"South Atlantic\", \"Pacific\", \"Mountain\",\n",
    "        \"East North Central\", \"East North Central\", \"West North Central\", \"West North Central\", \"East South Central\",\n",
    "        \"West South Central\", \"New England\", \"South Atlantic\", \"New England\", \"East North Central\",\n",
    "        \"West North Central\", \"East South Central\", \"West North Central\", \"Mountain\", \"West North Central\",\n",
    "        \"Mountain\", \"New England\", \"Mid-Atlantic\", \"Mountain\", \"Mid-Atlantic\", \"South Atlantic\",\n",
    "        \"West North Central\", \"East North Central\", \"West South Central\", \"Pacific\", \"Mid-Atlantic\",\n",
    "        \"New England\", \"South Atlantic\", \"West North Central\", \"East South Central\", \"West South Central\",\n",
    "        \"Mountain\", \"New England\", \"South Atlantic\", \"Pacific\", \"South Atlantic\", \"East North Central\", \"Mountain\"\n",
    "    ],\n",
    "    \"state\": [\n",
    "        \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "        \"Delaware\", \"District of Columbia\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",\n",
    "        \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\",\n",
    "        \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "        \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\",\n",
    "        \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\",\n",
    "        \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\",\n",
    "        \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\",\n",
    "        \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "    ],\n",
    "    \"individuals\": [\n",
    "        2570.0, 1434.0, 7259.0, 2280.0, 109008.0, 7607.0, 2280.0,\n",
    "        708.0, 3770.0, 21443.0, 6943.0, 4131.0, 1297.0,\n",
    "        6752.0, 3776.0, 1711.0, 1443.0, 2735.0,\n",
    "        2540.0, 1450.0, 4914.0, 6811.0, 5209.0,\n",
    "        3993.0, 1024.0, 3776.0, 983.0, 1745.0,\n",
    "        7058.0, 835.0, 6048.0, 1949.0, 39827.0,\n",
    "        6451.0, 467.0, 6929.0, 2823.0, 11139.0,\n",
    "        8163.0, 747.0, 3082.0, 836.0, 6139.0,\n",
    "        19199.0, 1904.0, 780.0, 3928.0, 16424.0, 1021.0, 2740.0, 434.0\n",
    "    ],\n",
    "    \"family_members\": [\n",
    "        864.0, 582.0, 2606.0, 432.0, 20964.0, 3250.0, 1696.0,\n",
    "        374.0, 3134.0, 9587.0, 2556.0, 2399.0, 715.0,\n",
    "        3891.0, 1482.0, 1038.0, 773.0, 953.0,\n",
    "        519.0, 1066.0, 2230.0, 13257.0, 3142.0,\n",
    "        3250.0, 328.0, 2107.0, 422.0, 676.0,\n",
    "        486.0, 615.0, 3350.0, 602.0, 52070.0,\n",
    "        2817.0, 75.0, 3320.0, 1048.0, 3337.0,\n",
    "        5349.0, 354.0, 851.0, 323.0, 1744.0,\n",
    "        6111.0, 972.0, 511.0, 2047.0, 5880.0, 222.0, 2167.0, 205.0\n",
    "    ],\n",
    "    \"state_pop\": [\n",
    "        4887681, 735139, 7158024, 3009733, 39461588, 5691287, 3571520,\n",
    "        965479, 701547, 21244317, 10511131, 1420593, 1750536,\n",
    "        12723071, 6695497, 3148618, 2911359, 4461153,\n",
    "        4659690, 1339057, 6035802, 6882635, 9984072,\n",
    "        5606249, 2981020, 6121623, 1060665, 1925614,\n",
    "        3027341, 1353465, 8886025, 2092741, 19530351,\n",
    "        10381615, 758080, 11676341, 3940235, 4181886,\n",
    "        12800922, 1058287, 5084156, 878698, 6771631,\n",
    "        28628666, 3153550, 624358, 8501286, 7523869, 1804291, 5807406, 577601\n",
    "    ]\n",
    "}\n",
    "\n",
    "homelessness = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fef5ac",
   "metadata": {},
   "source": [
    "## Exercise: Adding new columns\n",
    "\n",
    "When working with data, you’ll often need to **generate new columns** from existing ones. This process is commonly referred to as **feature engineering** or **data transformation**.\n",
    "\n",
    "You can:\n",
    "- Add new columns from scratch.\n",
    "- Derive columns using arithmetic or logical operations on existing data.\n",
    "\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "The `homelessness` DataFrame contains estimates of homelessness for each U.S. state in 2018:\n",
    "\n",
    "- `individuals`: Number of homeless individuals *not* in a family with children.\n",
    "- `family_members`: Number of homeless individuals *in* families with children.\n",
    "- `state_pop`: Total population of the state.\n",
    "\n",
    "`pandas` is already imported as `pd`.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Create a new column named **`total_homeless`** that represents the **sum** of `individuals` and `family_members`.\n",
    "2. Add another column called **`percent_homeless`** that shows the **proportion** of homeless people to the state’s total population.\n",
    "3. Print the updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0101b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop  \\\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681   \n",
      "1             Pacific      Alaska       1434.0           582.0     735139   \n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024   \n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733   \n",
      "4             Pacific  California     109008.0         20964.0   39461588   \n",
      "\n",
      "   total_homeless  percent_homeless  \n",
      "0          3434.0          0.000703  \n",
      "1          2016.0          0.002742  \n",
      "2          9865.0          0.001378  \n",
      "3          2712.0          0.000901  \n",
      "4        129972.0          0.003294  \n"
     ]
    }
   ],
   "source": [
    "# Compute the total number of homeless individuals\n",
    "homelessness[\"total_homeless\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"]\n",
    "\n",
    "# Calculate the proportion of homeless individuals in the total population\n",
    "homelessness[\"percent_homeless\"] = homelessness[\"total_homeless\"] / homelessness[\"state_pop\"]\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(homelessness.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00559dd8",
   "metadata": {},
   "source": [
    "## Exercise: Combo-attack!\n",
    "\n",
    "You've now practiced the four most essential data wrangling techniques:\n",
    "- Sorting rows\n",
    "- Selecting columns\n",
    "- Filtering rows\n",
    "- Creating new columns\n",
    "\n",
    "Now it's time to combine them all to answer a powerful analytical question:\n",
    "\n",
    "### Question\n",
    "**Which U.S. states have more than 20 homeless individuals per 10,000 residents?**\n",
    "\n",
    "Let’s find out by putting together multiple pandas operations in sequence.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Create a new column** `indiv_per_10k` to calculate the number of homeless individuals per 10,000 people in each state.\n",
    "2. **Filter the DataFrame** to include only rows where `indiv_per_10k` is greater than 20.\n",
    "3. **Sort the filtered DataFrame** in descending order based on `indiv_per_10k`.\n",
    "4. **Select only** the `state` and `indiv_per_10k` columns for the final output.\n",
    "5. **Print the result**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8c27a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Add column for individuals per 10k people\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"]\n",
    "\n",
    "# Step 2: Filter states where the rate exceeds 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Step 3: Sort the filtered data in descending order\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# Step 4: Select only relevant columns\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# Step 5: Display the outcome\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
